{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# detector = hub.load(\"https://tfhub.dev/tensorflow/efficientdet/lite2/detection/1\")\n",
    "detector = tf.keras.models.load_model(\"efficientdet_lite2_detection_1\")\n",
    "model = tf.keras.models.load_model('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectangle_to_square(coords):\n",
    "    # get the coordinates of the rectangle\n",
    "    ymin, xmin, ymax, xmax = coords\n",
    "    \n",
    "    # calculate the width and height of the rectangle\n",
    "    width = xmax - xmin\n",
    "    height = ymax - ymin\n",
    "    \n",
    "    # calculate the center of the rectangle\n",
    "    cx = xmin + (width / 2)\n",
    "    cy = ymin + (height / 2)\n",
    "    \n",
    "    # determine the length of the square\n",
    "    length = max(width, height)\n",
    "    \n",
    "    # calculate the new coordinates of the square\n",
    "    square_coords = [\n",
    "        int(cy - (length / 2)),\n",
    "        int(cx - (length / 2)),\n",
    "        int(cy + (length / 2)),\n",
    "        int(cx + (length / 2))\n",
    "    ]\n",
    "    \n",
    "    return square_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n"
     ]
    }
   ],
   "source": [
    "# cap = cv2.VideoCapture(1)\n",
    "\n",
    "# #Capture frame-by-frame\n",
    "# ret, frame = cap.read()\n",
    "\n",
    "# frame = cv2.imread('common_photos/envelopes/IMG_3629.jpg')\n",
    "frame = cv2.imread('common_photos/test/PXL_20230427_171056248.jpg')\n",
    "\n",
    "width = 512\n",
    "height = 512\n",
    "\n",
    "#Resize to respect the input_shape\n",
    "inp = cv2.resize(frame, (width , height ))\n",
    "\n",
    "#Convert img to RGB\n",
    "rgb = cv2.cvtColor(inp, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#Is optional but i recommend (float convertion and convert img to tensor image)\n",
    "rgb_tensor = tf.convert_to_tensor(rgb, dtype=tf.uint8)\n",
    "\n",
    "#Add dims to rgb_tensor\n",
    "rgb_tensor = tf.expand_dims(rgb_tensor , 0)\n",
    "\n",
    "boxes, scores, classes, num_detections = detector(rgb_tensor)\n",
    "\n",
    "pred_boxes = boxes.numpy()[0].astype('int')\n",
    "pred_scores = scores.numpy()[0]\n",
    "\n",
    "#loop throughout the detections and place a box around it  \n",
    "for score, (ymin,xmin,ymax,xmax) in zip(pred_scores, pred_boxes):\n",
    "    if score < 0.2:\n",
    "        continue\n",
    "\n",
    "    # Transform rectangle into square to fit into NN\n",
    "    ymin,xmin,ymax,xmax = rectangle_to_square((ymin,xmin,ymax,xmax))\n",
    "\n",
    "    # Make sure ROI is within bounds of image\n",
    "    ymin = max(0, ymin)\n",
    "    ymax = min(512, ymax)\n",
    "    xmin = max(0, xmin)\n",
    "    xmax = min(512, xmax)\n",
    "\n",
    "    # Isolate part of image with object\n",
    "    object_region = frame[ymin:ymax, xmin:xmax]\n",
    "\n",
    "    # Reshape region to fit NN\n",
    "    object_region = cv2.resize(object_region, (160 , 160 ))\n",
    "\n",
    "    # convert image to RGB\n",
    "    object_tensor = cv2.cvtColor(object_region, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Transform region into tensor form\n",
    "    object_tensor = tf.convert_to_tensor(object_region, dtype=tf.uint32)\n",
    "\n",
    "    # Add dims to rgb_tensor\n",
    "    object_tensor = tf.expand_dims(object_tensor , 0)\n",
    "\n",
    "    # Use the pre-trained model to make a prediction\n",
    "    prediction = model.predict(object_tensor)[0]\n",
    "\n",
    "    # Get the predicted label\n",
    "    predictions = tf.nn.sigmoid(prediction)\n",
    "\n",
    "    label = (\"Compostable\" if predictions < 0.01 else \"Non-Compostable\")\n",
    "    confidence_score = (1-predictions if predictions < 0.01 else predictions)\n",
    "\n",
    "    label_text = f'{label} => {confidence_score[0]*100:.8f}% Confidence'\n",
    "        \n",
    "    img_boxes = cv2.rectangle(rgb,(xmin, ymax),(xmax, ymin),(0,255,0),1)      \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(img_boxes,label_text,(xmin, ymax-10), font, 0.5, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "#Display the resulting frame\n",
    "cv2.imshow('black and white',img_boxes)\n",
    "\n",
    "# When everything done, release the capture\n",
    "cv2.waitKey(0)\n",
    "# cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
